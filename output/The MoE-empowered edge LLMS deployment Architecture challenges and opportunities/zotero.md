- [1: Edgeshard: Efficient llm inference via collaborative edge computing](zotero://select/items/@zhang2024edgeshard)
- [2: Galaxy: A resource-efficient collaborative edge ai system for in-situ transformer inference](zotero://select/items/@ye2024galaxy)
- [3: On-device language models: A comprehensive review](zotero://select/items/@xu2024device)
- [4: Large language models: A survey](zotero://select/items/@minaee2024large)
- [5: Will llms scaling hit the wall? breaking barriers via distributed resources on massive edge devices](zotero://select/items/@shen2025will)
- [6: A review on edge large language models: Design, execution, and applications](zotero://select/items/@zheng2025review)
- [7: Edgemoe: Fast on-device inference of moe-based large language models](zotero://select/items/@yi2023edgemoe)
- [8: Wdmoe: Wireless distributed large language models with mixture of experts](zotero://select/items/@xue2024wdmoe)
- [9: High-speed data communication with advanced networks in large language model training](zotero://select/items/@dai2024high)
- [10: RDMA transports in datacenter networks: survey](zotero://select/items/@hu2024rdma)
- [11: Llmcad: Fast and scalable on-device large language model inference](zotero://select/items/@xu2023llmcad)
- [12: Mobile edge intelligence for large language models: A contemporary survey](zotero://select/items/@qu2025mobile)
- [13: Communication-efficient distributed on-device llm inference over wireless networks](zotero://select/items/@zhang2025communication)
- [14: DILEMMA: Joint LLM Quantization and Distributed LLM Inference Over Edge Computing Systems](zotero://select/items/@hosseinzadeh2025dilemma)
- [15: MoE $\^{} 2$: Optimizing Collaborative Inference for Edge Large Language Models](zotero://select/items/@jin2025moe)